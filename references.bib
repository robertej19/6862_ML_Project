@article{PhysRevD.55.7114,
  title = {Deeply Virtual Compton Scattering},
  author = {X.~Ji},
  journal = {Phys.~Rev.~D},
  volume = {55},
  issue = {11},
  pages = {7114--7125},
  numpages = {0},
  year = {1997},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevD.55.7114},
}

@article{BURKERT2020163419,
title = {The CLAS12 Spectrometer at Jefferson Laboratory},
journal = {Nucl.~Inst.~and Meth.~A},
volume = {959},
pages = {163419},
year = {2020},
issn = {0168-9002},
doi = {https://doi.org/10.1016/j.nima.2020.163419},
author = {V.~D.~Burkert and others},
keywords = {CLAS12, Magnetic spectrometer, Electromagnetic physics, Large acceptance, Luminosity},
}

@article{10.1093/ptep/ptaa104,
    author = {P.~A.~Zyla and others},
    title = "{Review of Particle Physics}",
    journal = {Progress of Theoretical and Experimental Physics},
    volume = {2020},
    number = {8},
    year = {2020},
    abstract = "{The Review summarizes much of particle physics and cosmology. Using data from previous editions, plus 3,324 new measurements from 878 papers, we list, evaluate, and average measured properties of gauge bosons and the recently discovered Higgs boson, leptons, quarks, mesons, and baryons. We summarize searches for hypothetical particles such as supersymmetric particles, heavy bosons, axions, dark photons, etc. Particle properties and search limits are listed in Summary Tables. We give numerous tables, figures, formulae, and reviews of topics such as Higgs Boson Physics, Supersymmetry, Grand Unified Theories, Neutrino Mixing, Dark Energy, Dark Matter, Cosmology, Particle Detectors, Colliders, Probability and Statistics. Among the 120 reviews are many that are new or heavily revised, including a new review on High Energy Soft QCD and Diffraction and one on the Determination of CKM Angles from B Hadrons.The Review is divided into two volumes. Volume 1 includes the Summary Tables and 98 review articles. Volume 2 consists of the Particle Listings and contains also 22 reviews that address specific aspects of the data presented in the Listings.The complete Review (both volumes) is published online on the website of the Particle Data Group (pdg.lbl.gov) and in a journal. Volume 1 is available in print as the PDG Book. A Particle Physics Booklet with the Summary Tables and essential tables, figures, and equations from selected review articles is available in print and as a web version optimized for use on phones as well as an Android app.}",
    issn = {2050-3911},
    doi = {10.1093/ptep/ptaa104},
    note = {083C01},
    eprint = {https://academic.oup.com/ptep/article-pdf/2020/8/083C01/34673722/ptaa104.pdf},
}




@article{PhysRevLett.115.212003,
  title = {Cross Sections for the Exclusive Photon Electroproduction on the Proton and Generalized Parton Distributions},
  author = {H.~S.~Jo and others},
  collaboration = {CLAS Collaboration},
  journal = {Phys.~Rev.~Lett.},
  volume = {115},
  issue = {21},
  pages = {212003},
  numpages = {7},
  year = {2015},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.115.212003},
}

%url = {https://cds.cern.ch/record/2707778/files/CERN-THESIS-2020-003.pdf}
@mastersthesis{Viljoen2020,
    author = {C.~G.~Viljoen},
    title = {Machine Learning for Particle Identification \& Deep Generative Models Towards Fast Simulations For The ALICE Transistion Radiation Detector at CERN},
    school = {University of Cape Town},
    year = {2020}
}

%https://arxiv.org/abs/1807.02876
@article{Albertsson2018,
title = {Machine Learning in High Energy Physics Community White Paper},
journal = {Journal of Physics: Conference Series},
volume = {1085},
year = {2018},
issn = {022008},
author = {K.~Albertsson and others},
}

%https://arxiv.org/pdf/1705.02355.pdf
@article{Paganini2017,
title = {Accelerating Science with Generative Adversarial Networks: An Application to 3D Particle Showers in Multi-Layer Calorimeters},
author = {M.~Paganini and others},
journal = {ArXiv},
year = {2017},
}

%How can this paper exist in one of top rows?
@inproceedings{wehenkel2019unconstrained,
  title={Unconstrained monotonic neural networks},
  author={A.~Wehenkel and G.~Louppe},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1543--1553},
  year={2019}
}



@article{AGOSTINELLI2003250,
title = {Geant4—a simulation toolkit},
journal = {Nucl.~Inst.~and Meth.~A},
volume = {506},
number = {3},
pages = {250-303},
year = {2003},
issn = {0168-9002},
doi = {https://doi.org/10.1016/S0168-9002(03)01368-8},
author = {S.~Agostinelli and others},
keywords = {Simulation, Particle interactions, Geometrical modelling, Software engineering, Object-oriented technology, Distributed software development},
abstract = {Geant4 is a toolkit for simulating the passage of particles through matter. It includes a complete range of functionality including tracking, geometry, physics models and hits. The physics processes offered cover a comprehensive range, including electromagnetic, hadronic and optical processes, a large set of long-lived particles, materials and elements, over a wide energy range starting, in some cases, from 250eV and extending in others to the TeV energy range. It has been designed and constructed to expose the physics models utilised, to handle complex geometries, and to enable its easy adaptation for optimal use in different sets of applications. The toolkit is the result of a worldwide collaboration of physicists and software engineers. It has been created exploiting software engineering and object-oriented technology and implemented in the C++ programming language. It has been used in applications in particle physics, nuclear physics, accelerator design, space engineering and medical physics.}
}



@article{PhysRevD.101.076002,
  title = {Event generation with normalizing flows},
  author = {C.~Gao and others},
  journal = {Phys. Rev. D},
  volume = {101},
  issue = {7},
  pages = {076002},
  numpages = {8},
  year = {2020},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevD.101.076002},
}

@ARTICLE{9089305,
  author={I.~{Kobyzev} and others},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Normalizing Flows: An Introduction and Review of Current Methods}, 
  year={2020},
  volume={},
  number={},
  pages={1-1},
  doi={10.1109/TPAMI.2020.2992934}}
  
  @misc{papamakarios2019normalizing,
      title={Normalizing Flows for Probabilistic Modeling and Inference}, 
      author={G.~Papamakarios and others},
      year={2019},
      eprint={1912.02762},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{Dinh15,
  author    = {L.~Dinh and others},
  title     = {{NICE:} Non-linear Independent Components Estimation},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Workshop Track Proceedings},
  year      = {2015},
}

@article{root,
title = {ROOT — A C++ framework for petabyte data storage, statistical analysis and visualization},
journal = {Computer Physics Communications},
volume = {180},
number = {12},
pages = {2499-2512},
year = {2009},
doi = {https://doi.org/10.1016/j.cpc.2009.08.005},
author = {I.~Antcheva and others},
keywords = {C++, Object-oriented, Framework, Interpreter, Data storage, Data analysis, Visualization},
abstract = {ROOT is an object-oriented C++ framework conceived in the high-energy physics (HEP) community, designed for storing and analyzing petabytes of data in an efficient way. Any instance of a C++ class can be stored into a ROOT file in a machine-independent compressed binary format. In ROOT the TTree object container is optimized for statistical data analysis over very large data sets by using vertical data storage techniques. These containers can span a large number of files on local disks, the web, or a number of different shared file systems. In order to analyze this data, the user can chose out of a wide set of mathematical and statistical functions, including linear algebra classes, numerical algorithms such as integration and minimization, and various methods for performing regression analysis (fitting). In particular, the RooFit package allows the user to perform complex data modeling and fitting while the RooStats library provides abstractions and implementations for advanced statistical tools. Multivariate classification methods based on machine learning techniques are available via the TMVA package. A central piece in these analysis tools are the histogram classes which provide binning of one- and multi-dimensional data. Results can be saved in high-quality graphical formats like Postscript and PDF or in bitmap formats like JPG or GIF. The result can also be stored into ROOT macros that allow a full recreation and rework of the graphics. Users typically create their analysis macros step by step, making use of the interactive C++ interpreter CINT, while running over small data samples. Once the development is finished, they can run these macros at full compiled speed over large data sets, using on-the-fly compilation, or by creating a stand-alone batch program. Finally, if processing farms are available, the user can reduce the execution time of intrinsically parallel tasks — e.g. data mining in HEP — by using PROOF, which will take care of optimally distributing the work over the available resources in a transparent way.
Program summary
Program title: ROOT Catalogue identifier: AEFA_v1_0 Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AEFA_v1_0.html Program obtainable from: CPC Program Library, Queen's University, Belfast, N. Ireland Licensing provisions: LGPL No. of lines in distributed program, including test data, etc.: 3 044 581 No. of bytes in distributed program, including test data, etc.: 36 325 133 Distribution format: tar.gz Programming language: C++ Computer: Intel i386, Intel x86-64, Motorola PPC, Sun Sparc, HP PA-RISC Operating system: GNU/Linux, Windows XP/Vista, Mac OS X, FreeBSD, OpenBSD, Solaris, HP-UX, AIX Has the code been vectorized or parallelized?: Yes RAM: >55 Mbytes Classification: 4, 9, 11.9, 14 Nature of problem: Storage, analysis and visualization of scientific data Solution method: Object store, wide range of analysis algorithms and visualization methods Additional comments: For an up-to-date author list see: http://root.cern.ch/drupal/content/root-development-team and http://root.cern.ch/drupal/content/former-root-developers Running time: Depending on the data size and complexity of analysis algorithms References:[1]http://root.cern.ch.}
}


@article{ uproot,
	author = {{E.~Rodrigues} and others},
	title = {The Scikit HEP Project overview and prospects},
	DOI= "10.1051/epjconf/202024506028",
	journal = {EPJ Web Conf.},
	year = 2020,
	volume = 245,
	pages = "06028",
}



@article{phialia,
  title = {Equivariant Flow-Based Sampling for Lattice Gauge Theory},
  author = {G.~Kanwar and others},
  journal = {Phys. Rev. Lett.},
  volume = {125},
  issue = {12},
  pages = {121601},
  numpages = {6},
  year = {2020},
  month = {Sep},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.125.121601},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.125.121601}
}


@misc{ stan,
    author = {C.~Weisser},
    title = {The Search for Dark Photons at LHCb and Machine Learning in Particle Physics, Ph.~D.~Thesis (ongoing)}
}

@software{nflows,
  author       = {C.~Durkan and others},
  title        = {{nflows}: normalizing flows in {PyTorch}},
  month        = nov,
  year         = 2020,
  publisher    = {Zenodo},
  version      = {v0.14},
  doi          = {10.5281/zenodo.4296287},
  url          = {https://doi.org/10.5281/zenodo.4296287}
}

@misc{papamakarios2018masked,
      title={Masked Autoregressive Flow for Density Estimation}, 
      author={G.~Papamakarios and others},
      year={2018},
      eprint={1705.07057},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{Kullback51klDivergence,
  added-at = {2010-10-31T19:59:47.000+0100},
  author = {S.~Kullback and R.~A.~Leibler},
  biburl = {https://www.bibsonomy.org/bibtex/2560a5719c537c5c4a496bfebd4a21603/lee_peck},
  description = {Kullback , Leibler : On Information and Sufficiency},
  interhash = {f9d41d76a07383cca4c3a1a94c24d533},
  intrahash = {560a5719c537c5c4a496bfebd4a21603},
  journal = {Ann.~Math.~Statist.},
  keywords = {51 Kullback Leibler divergence kl},
  number = 1,
  pages = {79-86},
  timestamp = {2010-10-31T19:59:47.000+0100},
  title = {On Information and Sufficiency},
  volume = 22,
  year = 1951
}

@article{Dobrushin,
author = {R.~L.~Dobrushin},
title = {Prescribing a System of Random Variables by Conditional Distributions},
journal = {Theory of Probability \& Its Applications},
volume = {15},
number = {3},
pages = {458-486},
year = {1970},
doi = {10.1137/1115049},
}

@ARTICLE{jsd,
  author={J.~Lin},
  journal={IEEE Transactions on Information Theory}, 
  title={Divergence measures based on the Shannon entropy}, 
  year={1991},
  volume={37},
  number={1},
  pages={145-151},
  doi={10.1109/18.61115}}
  
@inproceedings{NEURIPS2019_2a084e55,
 author = {A.~Wehenkel and G.~Louppe},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Unconstrained Monotonic Neural Networks},
 volume = {32},
 year = {2019}
}


@InProceedings{pmlr-v37-germain15,
title = {MADE: Masked Autoencoder for Distribution Estimation},
author = {M.~Germain and others},
booktitle = {Proceedings of the 32nd International Conference on Machine Learning}, pages = {881--889}, year = {2015},
volume = {37}, series = {Proceedings of Machine Learning Research}, address = {Lille, France}, month = {07--09 Jul}, publisher = {PMLR} }

@inproceedings{NIPS2016_ddeebdee,
 author = {D.~P.~Kingma,  and others},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Improved Variational Inference with Inverse Autoregressive Flow},
 volume = {29},
 year = {2016}
}

